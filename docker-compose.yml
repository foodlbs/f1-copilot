version: '3.8'

services:
  # ==================== Infrastructure ====================
  redis:
    image: redis:7-alpine
    container_name: rag-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network

  # Ollama is optional - only needed if LLM_PROVIDER=ollama
  # Start with: docker compose --profile ollama up
  ollama:
    image: ollama/ollama:latest
    container_name: rag-ollama
    profiles:
      - ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 0"]
      interval: 10s
      timeout: 30s
      retries: 10
      start_period: 30s
    networks:
      - rag-network

  # ==================== Services ====================
  rag-service:
    build:
      context: ./services/rag-service
      dockerfile: Dockerfile
    container_name: rag-service
    ports:
      - "8001:8001"
    environment:
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
      - PINECONE_ENVIRONMENT=${PINECONE_ENVIRONMENT}
      - PINECONE_INDEX=${PINECONE_INDEX}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - WEB_SEARCH_ENABLED=${WEB_SEARCH_ENABLED:-true}
      - WEB_SEARCH_MAX_RESULTS=${WEB_SEARCH_MAX_RESULTS:-5}
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network

  kong:
    build:
      context: ./services/kong
      dockerfile: Dockerfile
    container_name: rag-kong
    ports:
      - "8000:8000"  # Proxy
      - "8444:8444"  # Admin API SSL
    environment:
      - KONG_DATABASE=off
      - KONG_DECLARATIVE_CONFIG=/usr/local/kong/declarative/kong.yml
      - KONG_PROXY_ACCESS_LOG=/dev/stdout
      - KONG_ADMIN_ACCESS_LOG=/dev/stdout
      - KONG_PROXY_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_ERROR_LOG=/dev/stderr
      - KONG_ADMIN_LISTEN=0.0.0.0:8444 ssl
      - KONG_PLUGINS=bundled
    depends_on:
      rag-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - rag-network

  frontend:
    build:
      context: ./services/frontend
      dockerfile: Dockerfile
      target: development
    container_name: rag-frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=${API_URL}
    volumes:
      - ./services/frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      kong:
        condition: service_healthy
    networks:
      - rag-network

volumes:
  redis_data:
  ollama_data:

networks:
  rag-network:
    driver: bridge
